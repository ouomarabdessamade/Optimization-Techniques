# Optimization Techniques

## Overview
In this project, we have implemented optimization algorithms from scratch for both single-variable and multi-variable functions.

### Single-variable Functions
For single-variable functions, the following algorithms have been implemented:

- **Bisection**
- **Dichotomous**
- **False Position**
- **Fibonacci**
- **Newton**
- **Golden Section**

### Multi-variable Functions
For multi-variable functions, the following algorithms have been implemented:

- **Gradient Descent**
- **Conjugate Gradient**
- **Newton  Multi-variable**
- **Quasi-Newton**

## File Descriptions
- [Bisection.ipynb](Bisection.py): Implementation of the Bisection algorithm for single-variable functions.
- [Dichotomous.ipynb](Dichotomous.py): Implementation of the Dichotomous algorithm for single-variable functions.
- [FalsePosition.ipynb](FalsePosition.py): Implementation of the False Position algorithm for single-variable functions.
- [Fibonacci.ipynb](Fibonacci.py): Implementation of the Fibonacci algorithm for single-variable functions.
- [Newton.ipynb](Newton.py): Implementation of the Newton algorithm for single-variable functions.
- [GoldenSection.ipynb](GoldenSection.py): Implementation of the Golden Section algorithm for single-variable functions.
- [GradientDescent.ipynb](GradientDescent.py): Implementation of the Gradient Descent algorithm for multi-variable functions.
- [ConjugateGradient.ipynb](ConjugateGradient.py): Implementation of the Conjugate Gradient algorithm for multi-variable functions.
- [NewtonMultivar.ipynb](NewtonMultivar.py): Implementation of the Newton Multivariable algorithm.
- [QuasiNewton.ipynb](QuasiNewton.py): Implementation of the Quasi-Newton algorithm for multi-variable functions.

Feel free to explore the notebooks for detailed code implementations and explanations. If you have any questions or suggestions, please don't hesitate to reach out.

Happy optimizing!
